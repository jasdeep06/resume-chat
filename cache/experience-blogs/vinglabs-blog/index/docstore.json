{"docstore/data": {"4d7d2fb2-2ecd-4985-9f27-c6b96b47000d": {"__data__": {"id_": "4d7d2fb2-2ecd-4985-9f27-c6b96b47000d", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04b45b97-4f8c-4648-b9c8-bae9518fc679", "node_type": "1", "metadata": {}, "hash": "ca6c77866de6f39987adbb4a8d533c91daf5beab4f2dbb0d031a5cab24a8cc02", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.", "start_char_idx": 0, "end_char_idx": 1002, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "04b45b97-4f8c-4648-b9c8-bae9518fc679": {"__data__": {"id_": "04b45b97-4f8c-4648-b9c8-bae9518fc679", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d7d2fb2-2ecd-4985-9f27-c6b96b47000d", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "2780deadb86946032509cbf5c212e1b20a2a8fdda540831ab49d17dc2a06d303", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc471be0-a083-4975-9bd8-9ec4965b0ab5", "node_type": "1", "metadata": {}, "hash": "5b2529fa48ee56b3e618377a82dc6884a0b9f80e0a22428f63a805d42e1f6d0c", "class_name": "RelatedNodeInfo"}}, "text": "Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.", "start_char_idx": 1010, "end_char_idx": 1950, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "fc471be0-a083-4975-9bd8-9ec4965b0ab5": {"__data__": {"id_": "fc471be0-a083-4975-9bd8-9ec4965b0ab5", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "04b45b97-4f8c-4648-b9c8-bae9518fc679", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "6bdb9b31b351b92d919dace8422baaa0a09477475fb85f4fad144f2215e942f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab", "node_type": "1", "metadata": {}, "hash": "d6faedc54da136fa7daa9209692312015b8412dfe147ed87013f2ea4c3b743e8", "class_name": "RelatedNodeInfo"}}, "text": "Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.\n            Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.", "start_char_idx": 1963, "end_char_idx": 3065, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab": {"__data__": {"id_": "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc471be0-a083-4975-9bd8-9ec4965b0ab5", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "3d084d16f1492dd5198967b19d28f917364bde93e83da540635ab991db6a8995", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab6c9e5c-6e9b-48d7-bdb7-d60303a5142f", "node_type": "1", "metadata": {}, "hash": "be1174482de578825e77c8133d670c61130bddb51911eb33c4ab64116417f290", "class_name": "RelatedNodeInfo"}}, "text": "The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.", "start_char_idx": 3077, "end_char_idx": 4239, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "ab6c9e5c-6e9b-48d7-bdb7-d60303a5142f": {"__data__": {"id_": "ab6c9e5c-6e9b-48d7-bdb7-d60303a5142f", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "9fd6742f120bce9a815977725b947f74cb288c8a611976e03bccee8e45fb75ee", "class_name": "RelatedNodeInfo"}}, "text": "After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens. The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 4247, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "b55ef008-6976-48e4-a659-8947b20a1ce6": {"__data__": {"id_": "b55ef008-6976-48e4-a659-8947b20a1ce6", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "910b4b99-47a0-420a-a798-46cacf76e605", "node_type": "1", "metadata": {}, "hash": "52f786e80a3a659265c3eb73ac906a465b25239237a4731d71e5bad0d09d180d", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.\n       Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.\n            Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.", "start_char_idx": 0, "end_char_idx": 2154, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "910b4b99-47a0-420a-a798-46cacf76e605": {"__data__": {"id_": "910b4b99-47a0-420a-a798-46cacf76e605", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b55ef008-6976-48e4-a659-8947b20a1ce6", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "d4cd3819dc28b2d695a39f1adff347fb424e79d748e40aa774d852dab23adf1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e09225c7-b1e3-4044-8e06-6dfc6b97a933", "node_type": "1", "metadata": {}, "hash": "9ad3812423762279e5d90750d23aa51694b339faca125db29c63999fab579797", "class_name": "RelatedNodeInfo"}}, "text": "Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.\n           The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.\n       After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens.", "start_char_idx": 2167, "end_char_idx": 4557, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "e09225c7-b1e3-4044-8e06-6dfc6b97a933": {"__data__": {"id_": "e09225c7-b1e3-4044-8e06-6dfc6b97a933", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-0", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "910b4b99-47a0-420a-a798-46cacf76e605", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "bde79e5711dfe8a26f28c33b3dd3a252cafb289c18ced03ba1af893acc23b6b1", "class_name": "RelatedNodeInfo"}}, "text": "The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 4558, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-0": {"__data__": {"id_": "node-0", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f9044837-f61d-4c42-97ec-0205b17362dc", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0662cac7-aed6-4f3b-bb63-25baf806ad30", "node_type": "1", "metadata": {}, "hash": "fa157cc11751eca829b27cb087fcb5161544f3ad14388cffedce081f4566ec63", "class_name": "RelatedNodeInfo"}}, "text": "4/6/24, 12:18 AM                                                  React App\n         Vinglabs Noesis Installation at ALPLA - A\n       About ALPLA                     Technical Report\n       ALPLA, otherwise     ALPLA Groupis an Austrian, international acting plastics manufacturer\n       and plastics recycler headquartered in Hard, specializing in blow-molded bottles and caps,\n       injection-molded parts, preforms and tubes. It is one of the largest producers of rigid plastic\n       packaging solutions worldwide, with a total of      177 production plantsin over          45\n       countriesworldwide, approx.        22,100 employees        and annual sales of   \u20ac 4.00 billion     in\n       2021. The annual production capacity of ALPLA\u2019s recycling companies, joint ventures and\n       collaborations amounts to approximately        203,000 tonnes of rPET          (recycled PET) and\n       74,000 tonnes of rHDPE           (recycled HDPE).ALPLA is the largest recycler of PET in\n       Europe.\n       Problem Statement\n       Vinglabs was tasked to install a monitoring system at one of        ALPLA\u2019ssubsidiary       PRT(PET\n       Recycling Team)       in W\u00f6llersdorf, Austria,30km off Vienna. The system was to be\n       installed on top of a conveyor which was the input feed to the plant. The feed consisted of\n       clear PET bottles(desirable) with other plastic impurities like non-clear PET bottles, non-\n       clear PP bottles, cans, cardboards etc. The feed was traveling at a speed of        3m/s   and the\n       conveyor was    1.8m wide. PRT wanted the following analytics from the monitoring system -\n            Utilization Factor of the plant        - Fraction of time throughout the day when the\n        conveyor was empty.\n            Opaque impurity detection           - For the PRT team, opaque bottles in the input stream\n        were a big concern because even a tiny percentage could negatively affect the output.\n            Non food detection- As the output of the PRT recycling plant is food grade PET\n        flakes, it is imperative for them to know the amount of non food material in their input\n        stream.\n            Real time analytics      - PRT wanted to eliminate the disconnect between the office and\n        the plant floor by implementing a real time analytics system to be proactive rather than\n        reactive.\nlocalhost:3000                                                                                                 1/84/6/24, 12:18 AM                                           React App\n               0:03 / 0:04\n      The Solution - Vinglabs Noesis\n      Camera Lens selection\n      The camera lens selection was crucial as the objects were traveling at a speed of3m/sand\n      were spread on a  1.8 m wide   conveyor. Following things were to be kept in mind -\n           The images would be clicked at  extremely low exposure to avoid motion blur.\n           Capturing images atlow exposure requires a lot of illumination         as lower the\n        exposure, less light will enter the camera.\n           The camera has to be a global shuttercamera to avoid distortion caused due to objects\n        moving at high speed.\n           The camera should have a  high pixel size   so as to incorporate as much light as\n        possible into the sensor.\nlocalhost:3000                                                                                    2/84/6/24, 12:18 AM                                                   React App\n            Increasing pixel size comes at a tradeoff to resolutionas sensor size remains\n        fixed.\n       Given these constraints, it was impossible to develop a single camera system that covers a\n       FOV of   1.8m. Thus it was decided to use       2 cameras     that would be adjacent to each other\n       capturing the left and right half of the conveyor respectively.\n       Given these variables, the constant that could be relied upon was the resolution of the\n       camera. Since it was known the minimum feature size (this is the minimum distance between\n       the features that camera lens system can resolve) to be captured was            2mm, the minimum\n       resolution of the camera was determined to be         2MP.\n       After carefully considering all the options, running some tests and availability constraints, it\n       was decided to go forward with-\n            2 LUCID Vision Labs Triton\u2122 TRI071S-CC, Sony IMX428, 7.1MP\n            Color Camera coupled with Fujinon CF12ZA-1S 12mm f/1.8 Machine Vision\n        C-Mount Lens. The IMX428 has a very large pixel pitch of 4.5um.\n       Lighting\n       Capturing images at a very low exposure requires a lot of lighting to capture a well lit image.", "start_char_idx": 0, "end_char_idx": 4726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-0", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "2612ae24-2b82-4e69-8894-252b56e41cb9": {"__data__": {"id_": "2612ae24-2b82-4e69-8894-252b56e41cb9", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a71e765-0dd8-4e80-b9f1-f429d1d75655", "node_type": "1", "metadata": {}, "hash": "d7ea08f4571fadcc3b41c1babe3aadb955f0ad8e0acd8173cf1941740a990ab9", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.", "start_char_idx": 0, "end_char_idx": 1183, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "8a71e765-0dd8-4e80-b9f1-f429d1d75655": {"__data__": {"id_": "8a71e765-0dd8-4e80-b9f1-f429d1d75655", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2612ae24-2b82-4e69-8894-252b56e41cb9", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "a9b4fe4f755b14b418d9ae46fb60759be8f1274e80c0837edc2b5878973c65d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "585c9ff4-6d61-4dca-acf3-a77fe2e5355f", "node_type": "1", "metadata": {}, "hash": "bc02e4006bc68c1cd49dafeca88493d61cc57cdfdab1ff12c7ebfa947085be77", "class_name": "RelatedNodeInfo"}}, "text": "To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.", "start_char_idx": 1196, "end_char_idx": 2243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "585c9ff4-6d61-4dca-acf3-a77fe2e5355f": {"__data__": {"id_": "585c9ff4-6d61-4dca-acf3-a77fe2e5355f", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8a71e765-0dd8-4e80-b9f1-f429d1d75655", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "221ecd3376f86b40ff1a5366fb441cd123671f723d8f7b842d01ab9d3c63633d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b", "node_type": "1", "metadata": {}, "hash": "320508d0d95e9f2deeca67736e169e5f792b4b5caea7cbfa2423686f1dd0323e", "class_name": "RelatedNodeInfo"}}, "text": "We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.", "start_char_idx": 2251, "end_char_idx": 3926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b": {"__data__": {"id_": "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "585c9ff4-6d61-4dca-acf3-a77fe2e5355f", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4ff3bbd107c1ea457fa4076338d566f183657d76444b8fb215ad54c606a6fc21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "affe346d-a4e2-45c3-ab03-c117671be14e", "node_type": "1", "metadata": {}, "hash": "5571b767688ec3501dbaeb9dc3198d002b3f3992eef8a51514aaf8a41c1b962d", "class_name": "RelatedNodeInfo"}}, "text": "Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.", "start_char_idx": 3939, "end_char_idx": 4953, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "affe346d-a4e2-45c3-ab03-c117671be14e": {"__data__": {"id_": "affe346d-a4e2-45c3-ab03-c117671be14e", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "a384683e68cf59351869a34b0da11e0e50edc596d87423a3160a8b757613e22b", "class_name": "RelatedNodeInfo"}}, "text": "localhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4954, "end_char_idx": 5716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "8e6f7c54-2e87-400f-b15a-4b647fe841c8": {"__data__": {"id_": "8e6f7c54-2e87-400f-b15a-4b647fe841c8", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ebeac946-b12b-40b5-af69-d96795c3a384", "node_type": "1", "metadata": {}, "hash": "c9ef2dd5a73c6efbd69ad872637c7a8b5311c3bfad8e0eebbb61d17f9305eaa0", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.\n            To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.", "start_char_idx": 0, "end_char_idx": 2243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "ebeac946-b12b-40b5-af69-d96795c3a384": {"__data__": {"id_": "ebeac946-b12b-40b5-af69-d96795c3a384", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e6f7c54-2e87-400f-b15a-4b647fe841c8", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "11e8a3abc6e1507ede7c2542a6e3e987459e03b5c61610eb3d6d1e478be6e35e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08badb41-3654-458b-989e-9cc639328d13", "node_type": "1", "metadata": {}, "hash": "5571b767688ec3501dbaeb9dc3198d002b3f3992eef8a51514aaf8a41c1b962d", "class_name": "RelatedNodeInfo"}}, "text": "We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.\n            Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.", "start_char_idx": 2251, "end_char_idx": 4953, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "08badb41-3654-458b-989e-9cc639328d13": {"__data__": {"id_": "08badb41-3654-458b-989e-9cc639328d13", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-1", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ebeac946-b12b-40b5-af69-d96795c3a384", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "553da9a602907d109c17152481d5c71fcfdd641b76691a1d4d8af918c4ef4cdb", "class_name": "RelatedNodeInfo"}}, "text": "localhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4954, "end_char_idx": 5716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-1": {"__data__": {"id_": "node-1", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f9044837-f61d-4c42-97ec-0205b17362dc", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc79837a-1c5c-447e-b80e-84bf69f58422", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "775dde9e-7edc-4423-be4c-7102448d5642", "node_type": "1", "metadata": {}, "hash": "39a865198bf078df443295244c5a02c907e7352b8c982988f8d6f42efefae530", "class_name": "RelatedNodeInfo"}}, "text": "We used diffused rectangular LED light panels with a target lux of 10,000 on the surface of\n       the conveyor.\n       System design of ML pipeline\n       The ML pipeline consisted of following parts -\n                         Data Collection Data Labelling   Model Training  Error Analysis Model Deployment\n       Data Collection\n            In a fully operational plant, it is imperative to capture diverse data at different times\n        throughout the day as capturing data only during particular hours may lead to the\n        collection of a particular kind of data and thus lead to poor classifiers. Also, one cannot\n        collect all the data as it would be impossible to manage such huge amounts of data.\nlocalhost:3000                                                                                             3/84/6/24, 12:18 AM                                                 React App\n            We decided to collect a burst of   1000 images every 30 minutes             throughout the day.\n        The data would be saved to externally connected Solid State Drives and would be uploaded\n        automatically to cloud(S3) whenever the images are not being clicked.\n            To click and save images, a typical   multithreaded master-slave architecture was\n        used with a queue in between.           One thread was responsible for clicking images and\n        dumping into the queue and multiple threads were used for popping the queue and saving\n        the image to disk.\n       Splitting up the problem into multiple parts with multiple classifiers\n       There are two ways to solve a complex ML problem.\n            The first is totrain an end to end modelwhich takes in the captured images, does\n        the object detection and classification(of type of object,color and food/non food) in one\n        shot.\n            The other way is to  split the problem into multiple sub problems and sub\n        classifiers and combine the result. This is always preferable as-\n          1. It helps us track the real performance bottleneck of our pipeline thereby giving us a\n          targeted approach to solve the problem.\n          2. Smaller classifiers are easier to debug and run through the machine learning loop.\n       We split the problem into multiple classifiers as per the following flowchart -\nlocalhost:3000                                                                                               4/84/6/24, 12:18 AM             VINGLABS             PET RECYCLING  React App\n                            TECHNOLOGIES          TEAMAMombor of tho ALPLA Group\n                                                       Object\n                                                      Detection\n                                                       Bottle\n                                                      Classifier\n                                              No Bottle           Bottle\n                                       No Boltle                          CCior\n                                       Classifief                        Classilien\n                                                      Clear-Light Blue Gsreen Oiher\n                                                       FoNan\n                                                        Classilier\n                                                  Food Grade Non Font\n                                       PRT CLASSIFICATION CATEGORIES FOR LABELLING\n       The problem was split up into 1 object detection model, and 3 classifiers-\n            Object Detection      - YOLO and YOLO-like family of models\n            Bottle/Cans/Other Classifier          - Resnet, GoogleNet, Squeezenet, ShuffleNet,\n        EfficientNet family of models\n            Color(Clear,Light Blue/Brown/Green/Black/Opaque/Other) Classifier                           -\n        Specially designed models of classification family to deal with colors.\n            Food/Non Food Classifier- We used many visual markers like shape of the bottle,\n        transparency, brands etc. to detect non food bottles in input stream. A combination of\n        YOLO styled and classification styled model.\n       In the final deployment of models, the object detection model needed to process           8 images\n       and the  3 classifiers   needed to process    100 objects each, all in     1 sec.\n       Label - Train - Error Analysis loop\n       We extensively used    active learning     along with a team of multiple human labellers to label\n       millions of images in a short amount of time. Following tools were used throughout this loop\n       -    Pytorch   - To write models,training loops,data loaders etc.\n            Wandb     - To track models, dataset and training.\n            S3 - As object store.\n            Apache Airflow      - To orchestrate ETL pipelines involved in preprocessing.\n            Kubernetes- To scale across different nodes for tuning hyperparameters.\nlocalhost:3000                                                                                             5/84/6/24, 12:18 AM                                      Baseline   React App\n                                                     Model/Trained\n                               Preprocessing           Model            Manual Labelling\n                                EB         OPMrch  aw3        Au        Model Training\n       Model Deployment                              Error Analysis\n       All the models were deployed locally on an      AGX JETSON ORIN           with the stream of images\n       and models connected with a lightweight       RabbitMQ. This enabled objects being retained\n       even if there was a hit on execution speed of models.", "start_char_idx": 4734, "end_char_idx": 10450, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-1", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "cc887dec-4a74-4b54-95ea-ab7c7abedbb5": {"__data__": {"id_": "cc887dec-4a74-4b54-95ea-ab7c7abedbb5", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "21ab063c-f643-4b84-88e2-6167a23300fc", "node_type": "1", "metadata": {}, "hash": "49758b30e7d6de8105a71774e50542a9bd718675ff9333f11f492a14711053c8", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.", "start_char_idx": 0, "end_char_idx": 856, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "21ab063c-f643-4b84-88e2-6167a23300fc": {"__data__": {"id_": "21ab063c-f643-4b84-88e2-6167a23300fc", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc887dec-4a74-4b54-95ea-ab7c7abedbb5", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "87668f8da7d051aa9022d0a181f7bf298032a6a0c21c2b9904d5a749798594ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e111168a-3628-4c9b-b7d0-6d366179dbd7", "node_type": "1", "metadata": {}, "hash": "30a82def77076992da7259aa809d278a58d39d4022fbdf9a7d0dc5d9b36fe34f", "class_name": "RelatedNodeInfo"}}, "text": "Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.", "start_char_idx": 897, "end_char_idx": 2020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "e111168a-3628-4c9b-b7d0-6d366179dbd7": {"__data__": {"id_": "e111168a-3628-4c9b-b7d0-6d366179dbd7", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "21ab063c-f643-4b84-88e2-6167a23300fc", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "2b980ee500b8e2cb2698952bbbd698bdabbd675f32a9a8101fe06a15cc0b53f0", "class_name": "RelatedNodeInfo"}}, "text": "Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?                        4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 2065, "end_char_idx": 3140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "062bebe4-6606-4b92-a876-a81722c0af33": {"__data__": {"id_": "062bebe4-6606-4b92-a876-a81722c0af33", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "592aad94-3258-4ba1-8eaf-72808aea1e12", "node_type": "1", "metadata": {}, "hash": "f00b907de6756817f55cd0b4e348da50aff8c34fbbba4f48bf74fbf917fc6086", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.\n                                        Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.\n                                            Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?", "start_char_idx": 0, "end_char_idx": 2488, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "592aad94-3258-4ba1-8eaf-72808aea1e12": {"__data__": {"id_": "592aad94-3258-4ba1-8eaf-72808aea1e12", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "node-2", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "062bebe4-6606-4b92-a876-a81722c0af33", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "e59099822145a249f4052a777b945b2671e327c0944efb3790a3dd7b2aab2368", "class_name": "RelatedNodeInfo"}}, "text": "4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 2512, "end_char_idx": 3140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "node-2": {"__data__": {"id_": "node-2", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f9044837-f61d-4c42-97ec-0205b17362dc", "node_type": "4", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "673799bad9e81eec076fb725ca6633fec63dceb2b3e4541ff40dadea5cc2169f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0662cac7-aed6-4f3b-bb63-25baf806ad30", "node_type": "1", "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}, "hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "class_name": "RelatedNodeInfo"}}, "text": "We were able to consistently clock\n       800ms for inference 8 images/sec             end to end which involved running multiple\n       classifiers on 100 images/sec.\n       The Impact\n       Pet Recycling Team (PRT), a subsidiary of           ALPLA, is a PET recycler in Europe.\n       Vinglabs    installed their system at PRT W\u00f6llersdorf, Austria on       October 1st 2022. Through\n       real-time monitoring using Vinglabs proprietary AI        Noesis   and a highly interactive\n       dashboard   Athena, the installation achieved the following goals successfully -\n            Utilization factor of plant      - Through Noesis\u2019s real time bottle detection, it is now\n        possible for stakeholders to monitor the plant throughput in real time, thus enabling them\n        to detect the least productive times of the day to take corrective action.\n                                        Bottle            Others           Cans\n            Opaque impurity detection          - For PRT team, opaque bottles in input stream were a\n        big concern because even a tiny percentage could negatively affect the output.Through\n        Noesis\u2019s real time color detection, PRT is able to monitor and get notified about opaque\nlocalhost:3000                                                                                              6/84/6/24, 12:18 AM                                              React App\n       percentage in input stream.Along with opaque bottle detection Noesis also detects bottles\n       of different colors like green,blue etc. to give real time insights to the plant.\n                       Clear     Clear Sleeved  Green        Opaque      Others       Blue\n           Non food detection- As the output of PRT recycling plant is food grade PET flakes, it\n       is imperative for them to know the amount of non food material in their input stream.\n       Noesis uses many visual markers like shape of the bottle, transparency, brands etc. to\n       detect non food bottles in input stream.\n                                            Food               Non-Food\n           Visualizing analytics on Athena        - To visualize all the analytics and insights,\n       Vinglabs has provided PRT with a highly interactive dashboard \u201cAthena\u201d which gives them\n       live as well as historical view of insights generated by Noesis.\n              VINCLABS                        Plant Analytics  VINCLABS                        Plant Analytics\n              Icuaa?                        4574                                             4\n                                                                           LAAA\n              Throughput Analytics on Athena                       Color Analytics on Athena\n                                       VINCLABS                        Plant Analytics\n                                                                    41.,7J\nlocalhost:3000                                                                                                 7/84/6/24, 12:18 AM        React App\n               Food/Non food Analytics on Athena\nlocalhost:3000                            8/8", "start_char_idx": 10451, "end_char_idx": 13591, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "index_id": "node-2", "obj": null, "class_name": "IndexNode"}, "__type__": "3"}, "0defd070-bf0a-4567-a936-b28855a76cc9": {"__data__": {"id_": "0defd070-bf0a-4567-a936-b28855a76cc9", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p1_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to the technical considerations involved in capturing high-quality images of objects in motion, specifically on a conveyor belt moving at a speed of 3 meters per second and with a width of 1.8 meters. To achieve the desired outcome, several key factors are highlighted:\n\n1. The necessity for a camera lens that can handle the specific requirements of photographing fast-moving objects, which includes the ability to take pictures with very low exposure times to prevent motion blur.\n\n2. The importance of having sufficient illumination is emphasized, as lower exposure times mean less light is captured by the camera's sensor, necessitating a brighter light source to compensate for the reduced exposure.\n\n3. The camera must be equipped with a global shutter mechanism. This is critical to avoid the distortion that can occur when capturing images of objects moving at high speeds, as a global shutter captures the entire image simultaneously, unlike a rolling shutter which captures the image in a sequential manner, leading to potential distortion.\n\n4. Lastly, the camera should have a high pixel size. Larger pixels can capture more light, which is particularly important when dealing with low exposure photography, as it helps to improve the image quality under these challenging conditions.\n\nThese technical requirements are essential for ensuring that the images of the objects on the conveyor are captured with clarity and precision, despite the challenges posed by their rapid movement and the need for low exposure photography.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89947b20-1072-4c1a-948c-e0e590766a21": {"__data__": {"id_": "89947b20-1072-4c1a-948c-e0e590766a21", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p1_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The setup in question involves a sophisticated camera system designed to capture high-speed objects on a conveyor. The system is engineered to handle the challenges of photographing objects moving at 3 meters per second on a conveyor belt that is 1.8 meters wide. To achieve clear images without motion blur, the system uses a very low exposure setting, which necessitates additional illumination to compensate for the reduced light intake.\n\nMoreover, the camera is equipped with a global shutter mechanism, which is essential for eliminating the distortion that can occur when imaging fast-moving subjects. This type of shutter captures the entire image simultaneously, as opposed to a rolling shutter that scans the image and can cause distortions if the objects move during the scan.\n\nAdditionally, the camera boasts a high pixel size, which is beneficial for capturing more light on the sensor, further aiding in the creation of well-exposed images despite the low exposure setting. This combination of features ensures that the camera system can reliably capture sharp, undistorted images of objects as they travel quickly along the conveyor, making it an integral part of the solution provided by Vinglabs Noesis.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0234c4a8-fce8-4076-a35b-cdd5ccf95008": {"__data__": {"id_": "0234c4a8-fce8-4076-a35b-cdd5ccf95008", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p2_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a technical setup for capturing images in an industrial environment, specifically on a conveyor system. The setup includes two high-resolution cameras, each responsible for covering one half of the conveyor to ensure the entire field of view is captured. These cameras are equipped with large pixel pitch sensors to balance the need for resolution with the size of the sensor. The chosen cameras are from LUCID Vision Labs, with Sony IMX428 sensors, which are known for their large pixel size, and they are paired with Fujinon lenses.\n\nTo ensure the images are well-lit, especially when working with low exposure times, diffused LED light panels are employed to provide bright and even lighting across the conveyor's surface. The target illumination level is quite high, at 10,000 lux, to facilitate clear image capture.\n\nThe process also involves a machine learning (ML) pipeline, which is a sequence of stages designed to develop and deploy a machine learning model. This pipeline includes collecting diverse data across different times to avoid bias, labeling the data to train the model, training the model itself, analyzing errors to refine the model, and finally deploying the model for practical use. The emphasis on diversity in data collection and the management of large data volumes are critical for the success of the ML model in accurately classifying or identifying features in the images captured by the camera system.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8e8a7d69-5e32-4410-98fe-c45413f4ae84": {"__data__": {"id_": "8e8a7d69-5e32-4410-98fe-c45413f4ae84", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p3_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter involves a process where a series of captures are taken at regular intervals, with the intention of processing these captures for object detection and classification. The captures are stored on solid-state drives and are also uploaded to a cloud service for accessibility and further analysis.\n\nA multithreaded approach is employed to manage the capturing and saving of these captures efficiently. This involves a master-slave architecture with a queuing system, where one part of the system is dedicated to capturing and queuing, while other parts work on retrieving from the queue and saving to storage.\n\nFor the analysis of the captures, there are two methodologies discussed. One is an end-to-end model that processes the captures in a single step, handling object detection and classification tasks simultaneously. The other approach is a divided one, where the problem is broken down into smaller, more manageable sub-tasks, each handled by a separate classifier. This latter approach is favored for its ease of debugging, better performance tracking, and the ability to iterate more effectively through the machine learning development loop.\n\nThe process is conceptualized in a flowchart, which likely outlines the sequence of steps from capture to classification, detailing the division of tasks into sub-classifiers and how they interact or feed into each other to produce the final output. This flowchart would be a visual representation of the architecture and methodology of the system, providing a clear and structured overview of the process.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e42fc27a-5fea-4477-9d79-9127c5ae6327": {"__data__": {"id_": "e42fc27a-5fea-4477-9d79-9127c5ae6327", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p4_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided describes a sophisticated system for recycling PET bottles using a React application. It outlines a structured approach to classifying bottles for recycling purposes, employing various technologies and methodologies.\n\nThe system is designed to identify and sort bottles using object detection models, specifically mentioning the YOLO family of models for this purpose. Once objects are detected, they are further classified by type (bottle, can, or other), color (clear, light blue, brown, green, black, opaque, or other), and whether they are food-grade or non-food grade. This classification is achieved through a combination of different neural network architectures, including Resnet, GoogleNet, Squeezenet, ShuffleNet, and EfficientNet, as well as custom-designed models for color classification.\n\nThe process is highly efficient, with the object detection model processing eight objects and the three classifiers handling a hundred objects each within one second. This high throughput is essential for industrial-scale operations.\n\nTo ensure the accuracy of the models, an iterative process called \"Label - Train - Error Analysis loop\" is used. This involves active learning and the assistance of human labelers to quickly annotate millions of images. The tools used in this process include PyTorch for model development and training, Wandb for tracking, S3 for object storage, Apache Airflow for orchestrating ETL pipelines, and Kubernetes for scaling the computation across different nodes.\n\nThe system is part of a team effort within the ALPLA Group, indicating a collaborative and integrated", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a052508-e227-447a-a366-f21ecea07cdd": {"__data__": {"id_": "3a052508-e227-447a-a366-f21ecea07cdd", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p5_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a baseline React application used in a recycling context, specifically for PET recycling. The process involves several steps, starting with preprocessing, which is symbolized by the letters \"EB.\" This is followed by the use of a model or trained model, indicated by \"OPM,\" and then manual labeling, with the cryptic notation \"rch aw3 Au.\"\n\nThe deployment of the models is a critical step, and it's mentioned that this was done locally on an AGX JETSON ORIN. The setup included a stream of images and models connected with a lightweight RabbitMQ, which is a messaging protocol for communication. Despite a potential impact on the execution speed of the models, the system was able to maintain a performance of 800 milliseconds for inference on 8 images per second, end to end, while running multiple classifiers on 100 images per second. Error analysis is also a part of the process, although the details are not specified in the text.\n\nThe impact of this system is highlighted through its application at the Pet Recycling Team (PRT) facility in W\u00f6llersdorf, Austria. The proprietary AI Noesis and an interactive dashboard named Athena were installed to enable real-time monitoring. This setup allowed stakeholders to monitor plant throughput in real time and identify less productive times for corrective action. The real-time bottle detection through Noesis is particularly emphasized, as it aids in monitoring the plant's utilization factor.\n\nAdditionally, the system's ability to detect opaque impurities is", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03b900fc-6c23-4729-b6cf-11c563f5fd98": {"__data__": {"id_": "03b900fc-6c23-4729-b6cf-11c563f5fd98", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p5_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a recycling system that utilizes artificial intelligence for real-time monitoring and sorting of recyclable materials. The system is capable of identifying and classifying different types of objects, such as bottles and cans, as well as detecting impurities within the recycling stream. This technology is particularly adept at recognizing opaque items, which are a significant concern for recycling facilities due to their potential to negatively impact the quality of the recycled output.\n\nThe system has been implemented at a PET recycling facility in Austria, where it has contributed to the optimization of the plant's operations. By providing stakeholders with the ability to monitor plant throughput in real-time, the technology enables them to identify less productive periods and take corrective actions to improve efficiency. The AI-powered solution, named Noesis, is complemented by an interactive dashboard called Athena, which together enhance the facility's operational capabilities.\n\nThe deployment of the models for this system was carried out locally on advanced hardware, ensuring that object recognition could be maintained even with a slight reduction in the execution speed of the models. The system's performance metrics indicate that it can process a significant number of images per second, allowing for rapid and efficient sorting and analysis.\n\nOverall, the integration of this AI technology into the recycling process represents a significant advancement in the ability to sort and process recyclable materials more effectively, thereby contributing to the overall efficiency and sustainability of the recycling industry.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b72282b9-4871-46bf-aa95-e9249d315e3b": {"__data__": {"id_": "b72282b9-4871-46bf-aa95-e9249d315e3b", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a recycling plant's process of sorting and analyzing different types of plastic bottles. The process involves detecting various colors of bottles, such as green and blue, as well as identifying opaque bottles. This is crucial for the plant to gain real-time insights into the materials they are processing.\n\nThe plant uses a system called Noesis to detect non-food grade materials within the input stream. This is important because the output of the plant is food-grade PET flakes, and they need to ensure that non-food grade materials are not included. The system employs visual markers like the shape of the bottle, its transparency, and branding to identify non-food grade bottles.\n\nAdditionally, there is a mention of an interactive dashboard named Athena provided by Vinglabs. Athena allows the plant to visualize analytics and insights, offering both live and historical data generated by Noesis.\n\nFurthermore, there are references to throughput analytics and color analytics, which are likely features of the Athena dashboard, providing detailed information on the plant's operations and the material composition of the input stream.\n\nLastly, there is a mention of a local server address, suggesting that the analytics dashboard or some related service can be accessed through a web interface on the local network.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "288316f0-f4d2-4f92-883f-b5c13878ba00": {"__data__": {"id_": "288316f0-f4d2-4f92-883f-b5c13878ba00", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_2"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a recycling plant's process of sorting materials, specifically focusing on the differentiation between food-grade PET bottles and non-food-grade materials. The process involves a sophisticated detection system that can identify various bottle characteristics, such as color and transparency. This system is capable of recognizing not only clear bottles but also those that are colored, such as green and blue, as well as opaque bottles. The importance of this detection is underscored by the need for the plant to produce food-grade PET flakes, which necessitates a thorough understanding of the composition of the input stream.\n\nTo aid in the management and analysis of this sorting process, an interactive dashboard named \"Athena\" is utilized. This dashboard provides both live and historical data, offering insights into the plant's operations. It appears that the dashboard can display various analytics, including throughput and color analytics, which are essential for monitoring and optimizing the plant's performance.\n\nAdditionally, there are references to visual markers that are used to identify non-food bottles, suggesting that the system employs a range of criteria, including the shape of the bottle and branding, to ensure accurate sorting.\n\nThe text also includes some numerical data and what seems to be a reference to a local server or a web address, indicating that the system might be accessible through a network or online platform for monitoring and data analysis purposes.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41c64105-4032-4904-8463-e9f03a9322d5": {"__data__": {"id_": "41c64105-4032-4904-8463-e9f03a9322d5", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_3"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a sophisticated analytics dashboard provided by a company named Vinglabs. This dashboard, referred to as \"Athena,\" is designed to offer both live and historical data insights for a recycling plant that processes PET bottles. The dashboard is instrumental in identifying various types of bottles, such as clear, clear sleeved, green, opaque, blue, and others, which is crucial for ensuring the output consists of food-grade PET flakes.\n\nThe dashboard appears to be highly interactive and capable of displaying a range of analytics, including the detection of non-food grade materials within the input stream. This is achieved by analyzing visual markers like the shape of the bottle, transparency, and branding. The dashboard also seems to provide throughput analytics, which could be related to the volume of materials processed over time, and color analytics, which might involve the distribution of bottle colors within the input stream.\n\nAdditionally, there are indications of real-time insights being provided to the plant, which could help in optimizing the recycling process and ensuring the quality of the output. The interface likely includes graphical representations such as charts and graphs that depict the processing data in an easily interpretable format, enhancing the plant's operational efficiency and decision-making capabilities.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59ef5748-319a-4625-a9f1-11431ec8f627": {"__data__": {"id_": "59ef5748-319a-4625-a9f1-11431ec8f627", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The subject matter pertains to a sophisticated system designed to analyze and categorize different types of bottles for recycling purposes. This system, referred to as Noesis, is capable of identifying various bottle characteristics such as color and opacity. It plays a crucial role in ensuring that the output of a PET recycling plant is of food-grade quality by detecting non-food grade materials in the input stream.\n\nThe system uses visual markers like the shape of the bottle, its transparency, and branding to distinguish between food and non-food grade bottles. Additionally, the system can detect bottles of different colors, including clear, green, blue, and opaque, which is essential for providing real-time insights to the recycling plant.\n\nTo facilitate the monitoring and analysis of this data, a highly interactive dashboard named Athena is employed. This dashboard presents both live and historical data, offering a comprehensive view of the insights generated by Noesis. The dashboard includes various analytics such as throughput and color distribution, which are crucial for the plant's operations.\n\nThe interface of the dashboard appears to be user-friendly and visually oriented, with graphs and charts that display the processed color data in a clear and accessible manner. This includes a color distribution pie chart and a timeline that shows the fluctuations in the processing of different colored bottles over time. The dashboard also provides numerical data and percentages, which are essential for the plant's analytics and decision-making processes.\n\nThe system is part of a suite of technologies provided by a company that specializes in plant analytics, indicating a focus on industrial efficiency", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "807980b6-17d0-4af0-89fa-a27db8d3ca26": {"__data__": {"id_": "807980b6-17d0-4af0-89fa-a27db8d3ca26", "embedding": null, "metadata": {"author": "Jasdeep Singh Chhabra", "blog_title": "vinglabs blog", "path": "cache\\experience-blogs\\vinglabs-blog\\parsed\\images\\1418fbca-c562-4a4e-87d8-59ee7b830b91-img_p6_5"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "text": "The content you provided suggests a sophisticated system for sorting and analyzing materials in a recycling plant. This system, referred to as Noesis, is capable of identifying various types of bottles by their color and transparency, such as clear, green, blue, and opaque bottles. It is particularly focused on distinguishing between food-grade and non-food-grade materials, which is crucial for producing high-quality recycled PET flakes suitable for food packaging.\n\nAdditionally, there is a mention of an interactive dashboard named Athena, developed by Vinglabs, which provides real-time and historical data visualization of the plant's operations. This dashboard seems to offer a comprehensive view of the plant's analytics, including throughput and color analytics, ensuring that the plant operators have a clear understanding of the input stream's composition and the efficiency of the recycling process.\n\nThe system appears to be designed to enhance the efficiency of the recycling plant by providing detailed insights into the material composition, which can help in optimizing the sorting process and ensuring the purity of the recycled output. The use of visual markers like the shape of the bottle and brand identification further aids in the accurate sorting of materials.\n\nThe reference to \"localhost:3000\" indicates that the dashboard or the analytics platform is accessible through a local web server, likely for testing or internal use within the plant's network. This suggests that the plant operators can monitor and manage the recycling process through a local interface, which could be part of the plant's intranet or a dedicated terminal.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"4d7d2fb2-2ecd-4985-9f27-c6b96b47000d": {"doc_hash": "2780deadb86946032509cbf5c212e1b20a2a8fdda540831ab49d17dc2a06d303", "ref_doc_id": "node-0"}, "04b45b97-4f8c-4648-b9c8-bae9518fc679": {"doc_hash": "6bdb9b31b351b92d919dace8422baaa0a09477475fb85f4fad144f2215e942f0", "ref_doc_id": "node-0"}, "fc471be0-a083-4975-9bd8-9ec4965b0ab5": {"doc_hash": "3d084d16f1492dd5198967b19d28f917364bde93e83da540635ab991db6a8995", "ref_doc_id": "node-0"}, "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab": {"doc_hash": "9fd6742f120bce9a815977725b947f74cb288c8a611976e03bccee8e45fb75ee", "ref_doc_id": "node-0"}, "ab6c9e5c-6e9b-48d7-bdb7-d60303a5142f": {"doc_hash": "289f94e833bf572254fbb094817c83beede346797778e417a21ecdd04b2316dc", "ref_doc_id": "node-0"}, "b55ef008-6976-48e4-a659-8947b20a1ce6": {"doc_hash": "d4cd3819dc28b2d695a39f1adff347fb424e79d748e40aa774d852dab23adf1c", "ref_doc_id": "node-0"}, "910b4b99-47a0-420a-a798-46cacf76e605": {"doc_hash": "bde79e5711dfe8a26f28c33b3dd3a252cafb289c18ced03ba1af893acc23b6b1", "ref_doc_id": "node-0"}, "e09225c7-b1e3-4044-8e06-6dfc6b97a933": {"doc_hash": "60d272811fe81d918c2b965d93179dd2a254054fea2e3e5c646051a337bbadb9", "ref_doc_id": "node-0"}, "node-0": {"doc_hash": "4945c694a48c3d55b358677238b22ad55c57cdb0a087c93473a98507139bf929", "ref_doc_id": "f9044837-f61d-4c42-97ec-0205b17362dc"}, "2612ae24-2b82-4e69-8894-252b56e41cb9": {"doc_hash": "a9b4fe4f755b14b418d9ae46fb60759be8f1274e80c0837edc2b5878973c65d2", "ref_doc_id": "node-1"}, "8a71e765-0dd8-4e80-b9f1-f429d1d75655": {"doc_hash": "221ecd3376f86b40ff1a5366fb441cd123671f723d8f7b842d01ab9d3c63633d", "ref_doc_id": "node-1"}, "585c9ff4-6d61-4dca-acf3-a77fe2e5355f": {"doc_hash": "4ff3bbd107c1ea457fa4076338d566f183657d76444b8fb215ad54c606a6fc21", "ref_doc_id": "node-1"}, "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b": {"doc_hash": "a384683e68cf59351869a34b0da11e0e50edc596d87423a3160a8b757613e22b", "ref_doc_id": "node-1"}, "affe346d-a4e2-45c3-ab03-c117671be14e": {"doc_hash": "5fafd82d970ad5c4384a7e84c188dac385137464edb9a090f7c9d857aec8cd4f", "ref_doc_id": "node-1"}, "8e6f7c54-2e87-400f-b15a-4b647fe841c8": {"doc_hash": "11e8a3abc6e1507ede7c2542a6e3e987459e03b5c61610eb3d6d1e478be6e35e", "ref_doc_id": "node-1"}, "ebeac946-b12b-40b5-af69-d96795c3a384": {"doc_hash": "553da9a602907d109c17152481d5c71fcfdd641b76691a1d4d8af918c4ef4cdb", "ref_doc_id": "node-1"}, "08badb41-3654-458b-989e-9cc639328d13": {"doc_hash": "5fafd82d970ad5c4384a7e84c188dac385137464edb9a090f7c9d857aec8cd4f", "ref_doc_id": "node-1"}, "node-1": {"doc_hash": "ae93d047d1c51a6f200f0a5155a948cbc1b3cc256c90f4ced94f0cf3ab21c8ab", "ref_doc_id": "f9044837-f61d-4c42-97ec-0205b17362dc"}, "cc887dec-4a74-4b54-95ea-ab7c7abedbb5": {"doc_hash": "87668f8da7d051aa9022d0a181f7bf298032a6a0c21c2b9904d5a749798594ed", "ref_doc_id": "node-2"}, "21ab063c-f643-4b84-88e2-6167a23300fc": {"doc_hash": "2b980ee500b8e2cb2698952bbbd698bdabbd675f32a9a8101fe06a15cc0b53f0", "ref_doc_id": "node-2"}, "e111168a-3628-4c9b-b7d0-6d366179dbd7": {"doc_hash": "aff666267bbafc4f01100cedfdf3e202b8ae4458c1e65e5704247bd03d4d28fd", "ref_doc_id": "node-2"}, "062bebe4-6606-4b92-a876-a81722c0af33": {"doc_hash": "e59099822145a249f4052a777b945b2671e327c0944efb3790a3dd7b2aab2368", "ref_doc_id": "node-2"}, "592aad94-3258-4ba1-8eaf-72808aea1e12": {"doc_hash": "e31584fb194d5fbf7c3be050a53b7dc5c2c8aa9dbe5cd929f721330b8c25bb8c", "ref_doc_id": "node-2"}, "node-2": {"doc_hash": "1f8798fd004d59ec4bbba71117f09235fa391f6fd870be27a4cf3f808e66fd27", "ref_doc_id": "f9044837-f61d-4c42-97ec-0205b17362dc"}, "0defd070-bf0a-4567-a936-b28855a76cc9": {"doc_hash": "fb1c25e13d5fb6815a74a5afdb10d5c3f4897e4897149154f23cc363ced5f9db"}, "89947b20-1072-4c1a-948c-e0e590766a21": {"doc_hash": "412140edd596268253e6a64d37486efbd0df3b73a118937fd0f3301293f6eefe"}, "0234c4a8-fce8-4076-a35b-cdd5ccf95008": {"doc_hash": "c43738ee3cfb834fd07e7a7773034b2107333300a415407174d5e485857320fa"}, "8e8a7d69-5e32-4410-98fe-c45413f4ae84": {"doc_hash": "df4a4bf99b37abf37ae036fe784f63fd935b973667601f63be869fb1630f651b"}, "e42fc27a-5fea-4477-9d79-9127c5ae6327": {"doc_hash": "8c8591a4367ce5379fe10d0399a18269ef92dbe4c1de5d085c453306fab6e2a5"}, "3a052508-e227-447a-a366-f21ecea07cdd": {"doc_hash": "7b780ced131765e21a4b9ca71deac992229f70dd224b9868b02b92f93649c95f"}, "03b900fc-6c23-4729-b6cf-11c563f5fd98": {"doc_hash": "da9dead73c9b418144925e8d16e1989b8ac9de0d4281cd6594faf98eb25cec98"}, "b72282b9-4871-46bf-aa95-e9249d315e3b": {"doc_hash": "a23d3e59aa7e062020dc2c16aec88bc26a62c81facf2ecd4b82558a217876bf9"}, "288316f0-f4d2-4f92-883f-b5c13878ba00": {"doc_hash": "6b22dbdb9305060f791267ac6b42d88b5aab1e6527471e1906ba57d5e822278c"}, "41c64105-4032-4904-8463-e9f03a9322d5": {"doc_hash": "11f0e7efbe488c9e49da5964aebd2f620bdbc31398a192b2e8982b220f805100"}, "59ef5748-319a-4625-a9f1-11431ec8f627": {"doc_hash": "7afb7a7d7968842d5de2513211915404e5b2d14a0f1757b6f2f4e749c00fe69a"}, "807980b6-17d0-4af0-89fa-a27db8d3ca26": {"doc_hash": "47dc54e71618f817a989d07394e5bbe2bfa4f78b01e8af4c9d476deae8ef671a"}}, "docstore/ref_doc_info": {"node-0": {"node_ids": ["4d7d2fb2-2ecd-4985-9f27-c6b96b47000d", "04b45b97-4f8c-4648-b9c8-bae9518fc679", "fc471be0-a083-4975-9bd8-9ec4965b0ab5", "a31ac0df-ded7-4443-aadb-9e7ef4cbcdab", "ab6c9e5c-6e9b-48d7-bdb7-d60303a5142f", "b55ef008-6976-48e4-a659-8947b20a1ce6", "910b4b99-47a0-420a-a798-46cacf76e605", "e09225c7-b1e3-4044-8e06-6dfc6b97a933"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "f9044837-f61d-4c42-97ec-0205b17362dc": {"node_ids": ["node-0", "node-1", "node-2"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "node-1": {"node_ids": ["2612ae24-2b82-4e69-8894-252b56e41cb9", "8a71e765-0dd8-4e80-b9f1-f429d1d75655", "585c9ff4-6d61-4dca-acf3-a77fe2e5355f", "74f8b2a2-8cc4-4041-9ddb-d9939d99af4b", "affe346d-a4e2-45c3-ab03-c117671be14e", "8e6f7c54-2e87-400f-b15a-4b647fe841c8", "ebeac946-b12b-40b5-af69-d96795c3a384", "08badb41-3654-458b-989e-9cc639328d13"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}, "node-2": {"node_ids": ["cc887dec-4a74-4b54-95ea-ab7c7abedbb5", "21ab063c-f643-4b84-88e2-6167a23300fc", "e111168a-3628-4c9b-b7d0-6d366179dbd7", "062bebe4-6606-4b92-a876-a81722c0af33", "592aad94-3258-4ba1-8eaf-72808aea1e12"], "metadata": {"author": "Jasdeep Singh Chhabra", "title": "vinglabs blog"}}}}